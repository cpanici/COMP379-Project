{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != 'card_offer'].values\n",
    "y = data['card_offer'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=0,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdsc = StandardScaler().fit(X_train)\n",
    "X_train_std = stdsc.transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model, cross validate\n",
    "\n",
    "- For this part, the GridSearchCV object will try the different combos of parameters for us\n",
    "- To use it, we just pass the model and the parameters we want it to try in a dictionary.\n",
    "- Each key of the dictionary is associate with a parameter of the model, and each key is a list of values to try for that paramter\n",
    "- For example, LogisticRegression has parameters called 'penalty' and 'C', so I use those as keys and associate them with a list of values to try for that parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(random_state=0, solver='liblinear'),\n",
       "             param_grid={'C': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 1, 5,\n",
       "                               10, 50, 100, 500, 1000],\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "parameters = {'penalty': ['l1', 'l2'], \n",
    "              'C': [.0001, .0005, .001, .005,  .01, .05,  1, 5, 10, 50, 100, 500, 1000]}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "classifier = GridSearchCV(model, parameters, cv=skf)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out top 5 models according to mean test fold score\n",
    "- Look at mean_test_score column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.188196</td>\n",
       "      <td>0.070659</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>0.96375</td>\n",
       "      <td>0.96625</td>\n",
       "      <td>0.96750</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97250</td>\n",
       "      <td>0.96625</td>\n",
       "      <td>0.9575</td>\n",
       "      <td>0.96125</td>\n",
       "      <td>0.95750</td>\n",
       "      <td>0.96625</td>\n",
       "      <td>0.963875</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.250330</td>\n",
       "      <td>0.044806</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>0.96375</td>\n",
       "      <td>0.96375</td>\n",
       "      <td>0.96625</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.96500</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.96000</td>\n",
       "      <td>0.95875</td>\n",
       "      <td>0.96750</td>\n",
       "      <td>0.963375</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.304977</td>\n",
       "      <td>0.043820</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>5</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 5, 'penalty': 'l1'}</td>\n",
       "      <td>0.96375</td>\n",
       "      <td>0.96375</td>\n",
       "      <td>0.96625</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.96500</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.96000</td>\n",
       "      <td>0.95875</td>\n",
       "      <td>0.96750</td>\n",
       "      <td>0.963375</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.260307</td>\n",
       "      <td>0.043067</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>50</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 50, 'penalty': 'l1'}</td>\n",
       "      <td>0.96375</td>\n",
       "      <td>0.96375</td>\n",
       "      <td>0.96500</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.96375</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.96000</td>\n",
       "      <td>0.95875</td>\n",
       "      <td>0.96750</td>\n",
       "      <td>0.963125</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.278653</td>\n",
       "      <td>0.052250</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 100, 'penalty': 'l1'}</td>\n",
       "      <td>0.96375</td>\n",
       "      <td>0.96375</td>\n",
       "      <td>0.96500</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96750</td>\n",
       "      <td>0.96375</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.96000</td>\n",
       "      <td>0.95875</td>\n",
       "      <td>0.96750</td>\n",
       "      <td>0.963000</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "12       0.188196      0.070659         0.000499        0.000499       1   \n",
       "16       0.250330      0.044806         0.000599        0.000489      10   \n",
       "14       0.304977      0.043820         0.000606        0.000495       5   \n",
       "18       0.260307      0.043067         0.000599        0.000489      50   \n",
       "20       0.278653      0.052250         0.000598        0.000488     100   \n",
       "\n",
       "   param_penalty                       params  split0_test_score  \\\n",
       "12            l1    {'C': 1, 'penalty': 'l1'}            0.96375   \n",
       "16            l1   {'C': 10, 'penalty': 'l1'}            0.96375   \n",
       "14            l1    {'C': 5, 'penalty': 'l1'}            0.96375   \n",
       "18            l1   {'C': 50, 'penalty': 'l1'}            0.96375   \n",
       "20            l1  {'C': 100, 'penalty': 'l1'}            0.96375   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "12            0.96625            0.96750               0.96   \n",
       "16            0.96375            0.96625               0.96   \n",
       "14            0.96375            0.96625               0.96   \n",
       "18            0.96375            0.96500               0.96   \n",
       "20            0.96375            0.96500               0.96   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "12            0.97250            0.96625             0.9575   \n",
       "16            0.96875            0.96500             0.9600   \n",
       "14            0.96875            0.96500             0.9600   \n",
       "18            0.96875            0.96375             0.9600   \n",
       "20            0.96750            0.96375             0.9600   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "12            0.96125            0.95750            0.96625         0.963875   \n",
       "16            0.96000            0.95875            0.96750         0.963375   \n",
       "14            0.96000            0.95875            0.96750         0.963375   \n",
       "18            0.96000            0.95875            0.96750         0.963125   \n",
       "20            0.96000            0.95875            0.96750         0.963000   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "12        0.004557                1  \n",
       "16        0.003356                2  \n",
       "14        0.003356                2  \n",
       "18        0.003223                4  \n",
       "20        0.003021                5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classifier.cv_results_).sort_values(by='rank_test_score').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of best model: 0.959\n"
     ]
    }
   ],
   "source": [
    "best_model = LogisticRegression(penalty='l1', C=1, solver='liblinear', random_state=0)\n",
    "best_model.fit(X_train, y_train)\n",
    "print(f'Test set accuracy of best model: {best_model.score(X_test, y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
